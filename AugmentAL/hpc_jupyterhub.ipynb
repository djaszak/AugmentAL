{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c64acb2-32d0-4d47-a4e5-51136f9351f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d5f43e13db414dacbbb1441425129b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f250219a1ed47b6b2b095d367143d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442ac5cc09864005a87bf988bb6a980b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23019d4251434a07b901a93f8a23da16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e117bd241dd847baa92bec11a3163bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b34275bde14b4a87cd651aaf869d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e4d1a959d4a455ba8d1ef4d1703da48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f4b43282ec43f1b3c464651a4d87b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f42a16680744e5b0f155818729d04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s8822750/.local/lib/python3.10/site-packages/small_text/utils/annotations.py:67: ExperimentalWarning: The function from_arrays is experimental and maybe subject to change soon.\n",
      "  warnings.warn(f'The {subject} {func_or_class.__name__} is experimental '\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.95\n",
      "Test accuracy: 0.54\n",
      "Start while at time: 12:55:20\n",
      "End while at time: 12:56:02\n",
      "---------------\n",
      "Iteration #0 (40 samples)\n",
      "Train accuracy: 0.60\n",
      "Test accuracy: 0.51\n",
      "Stop: False\n",
      "Start while at time: 12:57:12\n",
      "End while at time: 12:58:35\n",
      "---------------\n",
      "Iteration #1 (60 samples)\n",
      "Train accuracy: 0.88\n",
      "Test accuracy: 0.58\n",
      "Stop: False\n",
      "Start while at time: 12:59:48\n",
      "End while at time: 13:00:30\n",
      "---------------\n",
      "Iteration #2 (80 samples)\n",
      "Train accuracy: 0.88\n",
      "Test accuracy: 0.56\n",
      "Stop: False\n",
      "Start while at time: 13:01:43\n",
      "End while at time: 13:02:24\n",
      "---------------\n",
      "Iteration #3 (100 samples)\n",
      "Train accuracy: 0.96\n",
      "Test accuracy: 0.67\n",
      "Stop: False\n",
      "Start while at time: 13:03:35\n",
      "End while at time: 13:04:17\n",
      "---------------\n",
      "Iteration #4 (120 samples)\n",
      "Train accuracy: 0.96\n",
      "Test accuracy: 0.65\n",
      "Stop: False\n",
      "Start while at time: 13:05:30\n",
      "End while at time: 13:06:12\n",
      "---------------\n",
      "Iteration #5 (140 samples)\n",
      "Train accuracy: 0.94\n",
      "Test accuracy: 0.72\n",
      "Stop: False\n",
      "Start while at time: 13:07:26\n",
      "End while at time: 13:08:49\n",
      "---------------\n",
      "Iteration #6 (160 samples)\n",
      "Train accuracy: 0.93\n",
      "Test accuracy: 0.74\n",
      "Stop: False\n",
      "Start while at time: 13:10:01\n",
      "End while at time: 13:10:42\n",
      "---------------\n",
      "Iteration #7 (180 samples)\n",
      "Train accuracy: 0.97\n",
      "Test accuracy: 0.81\n",
      "Stop: False\n",
      "Start while at time: 13:11:54\n",
      "End while at time: 13:12:36\n",
      "---------------\n",
      "Iteration #8 (200 samples)\n",
      "Train accuracy: 0.94\n",
      "Test accuracy: 0.74\n",
      "Stop: False\n",
      "Start while at time: 13:13:53\n",
      "End while at time: 13:14:35\n",
      "---------------\n",
      "Iteration #9 (220 samples)\n",
      "Train accuracy: 0.92\n",
      "Test accuracy: 0.74\n",
      "Stop: False\n",
      "Start while at time: 13:15:50\n",
      "End while at time: 13:17:13\n",
      "---------------\n",
      "Iteration #10 (240 samples)\n",
      "Train accuracy: 0.97\n",
      "Test accuracy: 0.78\n",
      "Stop: False\n",
      "Start while at time: 13:18:28\n",
      "End while at time: 13:19:51\n",
      "---------------\n",
      "Iteration #11 (260 samples)\n",
      "Train accuracy: 0.98\n",
      "Test accuracy: 0.78\n",
      "Stop: False\n",
      "Start while at time: 13:21:06\n",
      "End while at time: 13:21:47\n",
      "---------------\n",
      "Iteration #12 (280 samples)\n",
      "Train accuracy: 0.92\n",
      "Test accuracy: 0.78\n",
      "Stop: False\n",
      "Start while at time: 13:23:04\n",
      "End while at time: 13:24:27\n",
      "---------------\n",
      "Iteration #13 (300 samples)\n",
      "Train accuracy: 0.96\n",
      "Test accuracy: 0.82\n",
      "Stop: False\n",
      "Start while at time: 13:25:43\n",
      "End while at time: 13:26:25\n",
      "---------------\n",
      "Iteration #14 (320 samples)\n",
      "Train accuracy: 0.97\n",
      "Test accuracy: 0.81\n",
      "Stop: False\n",
      "Start while at time: 13:27:46\n",
      "End while at time: 13:29:09\n",
      "---------------\n",
      "Iteration #15 (340 samples)\n",
      "Train accuracy: 0.96\n",
      "Test accuracy: 0.81\n",
      "Stop: False\n",
      "Start while at time: 13:30:33\n",
      "End while at time: 13:31:56\n",
      "---------------\n",
      "Iteration #16 (360 samples)\n",
      "Train accuracy: 0.99\n",
      "Test accuracy: 0.80\n",
      "Stop: False\n",
      "Start while at time: 13:33:16\n",
      "End while at time: 13:33:57\n",
      "---------------\n",
      "Iteration #17 (380 samples)\n",
      "Train accuracy: 0.87\n",
      "Test accuracy: 0.76\n",
      "Stop: False\n",
      "Start while at time: 13:35:17\n",
      "End while at time: 13:35:58\n",
      "---------------\n",
      "Iteration #18 (400 samples)\n",
      "Train accuracy: 0.94\n",
      "Test accuracy: 0.77\n",
      "Stop: False\n",
      "Start while at time: 13:37:17\n"
     ]
    }
   ],
   "source": [
    "from core.loop import run_active_learning_loop\n",
    "from core.constants import Datasets, TransformerModels\n",
    "from datasets import load_dataset\n",
    "from nlpaug.augmenter import word as naw\n",
    "from core.augment import create_augmented_dataset\n",
    "\n",
    "query_strategies = [\n",
    "    # \"BreakingTies\",\n",
    "    # \"AugmentedSearchSpaceExtensionAndOutcomeQueryStrategy\",\n",
    "    \"AugmentedSearchSpaceExtensionQueryStrategy\",\n",
    "    # \"AugmentedOutcomesQueryStrategy\",\n",
    "    # \"AugmentedSearchSpaceExtensionAndOutcomeLeastConfidenceQueryStrategy\",\n",
    "    # \"AugmentedSearchSpaceExtensionLeastConfidenceQueryStrategy\",\n",
    "    # \"AugmentedOutcomesLeastConfidenceQueryStrategy\",\n",
    "]\n",
    "\n",
    "num_queries = 20\n",
    "num_samples = 20\n",
    "num_augmentations = 5\n",
    "\n",
    "datasets = [Datasets.ROTTEN.value]\n",
    "\n",
    "for dataset_name in datasets:\n",
    "\n",
    "    dataset = load_dataset(dataset_name)\n",
    "\n",
    "    raw_test = dataset[\"test\"]\n",
    "    raw_train = dataset[\"train\"]\n",
    "    raw_augmented_train, augmented_indices = create_augmented_dataset(\n",
    "        raw_train, naw.SynonymAug(aug_src=\"wordnet\"), n=num_augmentations\n",
    "    )\n",
    "\n",
    "    for query_strategy in query_strategies:\n",
    "        run_active_learning_loop(\n",
    "            raw_test,\n",
    "            raw_train,\n",
    "            raw_augmented_train,\n",
    "            augmented_indices,\n",
    "            num_queries=num_queries,\n",
    "            num_samples=num_samples,\n",
    "            num_augmentations=num_augmentations\n",
    "            if query_strategy != \"BreakingTies\"\n",
    "            else 0,\n",
    "            query_strategy=query_strategy,\n",
    "            model=TransformerModels.BERT.value,\n",
    "            device=\"cuda\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55e68e5-3318-4074-be2b-373c17f759bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch v2.x (Machine Learning)",
   "language": "python",
   "name": "pytorch_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
